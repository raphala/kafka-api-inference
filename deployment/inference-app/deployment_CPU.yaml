---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-python-inference-app-fastembed-cpu
  namespace: ${K8S_NAMESPACE}
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kafka-python-inference-app-fastembed-cpu
  template:
    metadata:
      labels:
        app: kafka-python-inference-app-fastembed-cpu
    spec:
      containers:
        - name: kafka-python-inference-app-fastembed-cpu
          image: ${DOCKER_IMAGE_URL}kafka-python-inference-app:latest-fastembed-cpu
          imagePullPolicy: Always
          env:
            - name: BOOTSTRAP_SERVER
              value: "${BOOTSTRAP_SERVER}"
            - name: SCHEMA_REGISTRY
              value: "${SCHEMA_REGISTRY}"
            - name: INPUT_TOPIC
              value: "inference-test-paper"
            - name: OUTPUT_TOPIC
              value: "inference-test-embedded-paper"
            - name: EXECUTION_PROVIDERS
              value: "CPUExecutionProvider"
            - name: EMBEDDING_MODEL
              value: "BAAI/bge-large-en-v1.5"
            - name: CHUNK_SIZE
              value: "512"
            - name: CHUNK_OVERLAP
              value: "32"
            - name: BATCH_SIZE
              value: "32"
            - name: LOG_LEVEL
              value: "INFO"
          resources:
            requests:
              cpu: "1"
              memory: "2Gi"
            limits:
              cpu: "3"
              memory: "8Gi"
