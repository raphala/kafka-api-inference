---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-python-inference-app-gpu
  namespace: personal-raphael-lachtner
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kafka-python-inference-app-gpu
  template:
    metadata:
      labels:
        app: kafka-python-inference-app-gpu
    spec:
      containers:
        - name: kafka-python-inference-app-gpu
          image: us.gcr.io/gcp-bakdata-cluster/kafka-python-inference-app:latest-gpu
          imagePullPolicy: Always
          env:
            - name: BOOTSTRAP_SERVER
              value: "strimzi-k8kafka-kafka-bootstrap.infrastructure.svc:9092"
            - name: SCHEMA_REGISTRY
              value: "http://k8kafka-cp-schema-registry.infrastructure.svc.cluster.local:8081"
            - name: INPUT_TOPIC
              value: "inference-test-paper"
            - name: OUTPUT_TOPIC
              value: "inference-test-embedded-paper"
            - name: EXECUTION_PROVIDERS
              value: "CUDAExecutionProvider,CPUExecutionProvider"
            - name: EMBEDDING_MODEL
              value: "BAAI/bge-large-en-v1.5"
            - name: CHUNK_SIZE
              value: "512"
            - name: CHUNK_OVERLAP
              value: "32"
            - name: BATCH_SIZE
              value: "32"
            - name: LOG_LEVEL
              value: "INFO"
          resources:
            requests:
              cpu: "1"
              memory: "2Gi"
              nvidia.com/gpu: "1"
            limits:
              cpu: "3"
              memory: "8Gi"
              nvidia.com/gpu: "1"
      nodeSelector:
        cloud.google.com/gke-accelerator: nvidia-l4
